
# LLM Public Opition Resources

[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT) 


Public Opinion Polling: a curated list of resources evaluating large language models for public opinion polling.

---

*Here are some other paper lists you might be interested in:*

💡 ![Last Commit](https://img.shields.io/github/last-commit/Neph0s/awesome-llm-role-playing-with-persona.svg)**[Persona Paper 1](https://github.com/Neph0s/awesome-llm-role-playing-with-persona/):** A list of papers related to role-playing/persona papers and resources and the inspiration for this list

💡 ![Last Commit](https://img.shields.io/github/last-commit/Sahandfer/PersonaPaper.svg)**[Persona Paper 2](https://github.com/Sahandfer/PersonaPaper):** A list of papers related to persona-based dialogue systems and personalized response generation.

💡 ![Last Commit](https://img.shields.io/github/last-commit/penguinnnnn/awesome-llm-and-society.svg)**[LLM and Society](https://github.com/penguinnnnn/awesome-llm-and-society):**  Papers on (1) Psychology of LLMs; (2) Biases in LLMs.

💡 ![Last Commit](https://img.shields.io/github/last-commit/zjunlp/LLMAgentPapers.svg)**[LLM Agent Papers](https://github.com/zjunlp/LLMAgentPapers):**  Papers on Large Language Model Agents.

## 🔔 News

- **2024-04-17 We are looking for collaborators interested in research on this topic. Contact us via email: C.Haensch@lmu.de**

## 📜Content

### US-centric papers

Argyle, L.P. et al. (2023) ‘Out of One, Many: Using Language Models to Simulate Human Samples’, Political Analysis, 31(3), pp. 337–351. doi:10.1017/pan.2023.2.

  - One of the most prominent proposals to use LLM for creating synthetic survey responses. Uses the term *silicon sampling*. Models examined include *GPT-3*. Thematic focus on U.S. politics and public opinion. Uses the 2012, 2016, and 2020 waves of the *American National Election Studies (ANES)* and Rothschild et al.’s “Pigeonholing Partisans” data as comparison.
  - Conclusion from the paper: "We then compare the silicon and human samples to demonstrate that the information contained in GPT-3 goes far beyond surface similarity. It is nuanced, multifaceted, and reflects the complex interplay between ideas, attitudes, and sociocultural context that characterize human attitudes. We suggest that language models with sufficient algorithmic fidelity thus constitute a novel and powerful tool to advance understanding of humans and society across a variety of disciplines."

Santurkar, S., Durmus, E., Ladhak, F., Lee, C., Liang, P., & Hashimoto, T. (2023). Whose Opinions Do Language Models Reflect?. arXiv preprint arXiv:2303.17548.

  - Focuses on the alignment of distribution between LLM generated text and US-American demographic groups. As part of the paper, they created *OpinionQA*, a dataset for evaluating LM output with those of 60 US demographic groups with a wide range of topics from abortion to automation, based on *Pew Research’s American Trends Panels*. Partly focuses on the comparison between different *base LMs (ada, davinci, davinci, j1-grande and j1-jumbo), and human feedback (HF)-tuned LMs that (text-* and j1-grande-v2-beta)*. Comparison on the level of group distribution, not on person level. 

#### Electoral data

#### Other attitudinal and value data

### Other countries

### Cross-country comparisons

---

## 💡  Contribution

### Contributing to this repo

🤲" **Join us in improving this repository!** Spotted any notable works we might have missed? We welcome your additions. Every contribution counts!   "

